{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 패키지 불러오기 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "# 그래프를 노트북 안에 그리기 위해 설정\n",
    "%matplotlib inline\n",
    "\n",
    "# 글꼴 경로 지정\n",
    "font_path = '../../data/malgun.ttf'  # 윈도우에 설치된 맑은 고딕 폰트 경로\n",
    "\n",
    "# 폰트 이름 얻어오기\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "# matplotlib의 rc(run command) 기능을 이용하여 글꼴 설정\n",
    "mpl.rc('font', family=font_name)\n",
    "\n",
    "# 유니코드에서  음수 부호 설정\n",
    "mpl.rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90852, 26)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "path = '../../data/Airbnb_London/listings.csv'\n",
    "\n",
    "london_lists = pd.read_csv(path)\n",
    "\n",
    "# 1차 선별한 컬럼 25개 중 22개 2차 선별 + 1개(숙소_예약가능_여부)\n",
    "# 최근 리뷰가 작성되었는지를 보기 위해 2개 컬럼 추가_240529 >> 'number_of_reviews_ltm' // 'last_review'\n",
    "# URL 컬럼 london_lists에 적용_240530\n",
    "\n",
    "columns_selected = ['id', 'listing_url', 'host_id', 'host_is_superhost', 'neighbourhood_cleansed', 'property_type', \\\n",
    "    'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'amenities', 'price', 'has_availability', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'last_review', 'review_scores_rating', 'review_scores_accuracy', \\\n",
    "    'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "# 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_total_listings_count', 'host_has_profile_pic', 'host_identity_verified', 'minimum_nights', 'maximum_nights', 'has_availability',\n",
    "\n",
    "# 선별한 컬럼만 적용\n",
    "london_lists = london_lists[columns_selected]\n",
    "\n",
    "# 변수 정리 \n",
    "london_lists = london_lists.rename(columns={\n",
    "    'id': '숙소_id',\n",
    "    'listing_url' : '숙소_url',\n",
    "    'host_id': '호스트_id',\n",
    "    # 'host_response_time': '답변_평균시간',\n",
    "    # 'host_response_rate': '문의_응답률',\n",
    "    # 'host_acceptance_rate': '예약_수락률',\n",
    "    'host_is_superhost': '슈퍼호스트',\n",
    "    # 'host_total_listings_count': '숙소_수',\n",
    "    # 'host_has_profile_pic' : '프로필_사진',\n",
    "    # 'host_identity_verified' : '호스트_신원',\n",
    "    'neighbourhood_cleansed': '숙소_지역',\n",
    "    'property_type' : '숙소_특징',\n",
    "    'room_type': '숙소_유형',\n",
    "    'accommodates': '수용_인원수',\n",
    "    'bathrooms': '욕실수',\n",
    "    'bedrooms': '침실수',\n",
    "    'beds': '침대수',\n",
    "    'amenities': '편의시설',\n",
    "    'price': '숙소_가격',\n",
    "    # 'minimum_nights': '최소_숙박일',\n",
    "    # 'maximum_nights': '최대_숙박일',\n",
    "    'has_availability' : '예약_가능여부',\n",
    "    'number_of_reviews': '리뷰수',\n",
    "    'number_of_reviews_ltm' : '12개월_리뷰수',\n",
    "    'number_of_reviews_l30d': '30일_리뷰수',\n",
    "    'last_review' : '마지막_리뷰',\n",
    "    'review_scores_rating': '리뷰점수',\n",
    "    'review_scores_accuracy': '숙소_정확성_리뷰점수',\n",
    "    'review_scores_cleanliness': '숙소_청결도_리뷰점수',\n",
    "    'review_scores_checkin': '숙소_체크인_리뷰점수',\n",
    "    'review_scores_communication': '숙소_소통_리뷰점수',\n",
    "    'review_scores_location': '숙소_위치_리뷰점수',\n",
    "    'review_scores_value': '숙소_가격_리뷰점수',\n",
    "    'reviews_per_month': '평균_리뷰수'\n",
    " \n",
    "})\n",
    "\n",
    "temp = london_lists.copy()\n",
    "raw = london_lists.copy()\n",
    "\n",
    "# 컬럼명 확인\n",
    "london_lists.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38769, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰수가 0인 컬럼 조건 \n",
    "condition_review_0 = london_lists['리뷰수'] == 0\n",
    "\n",
    "# 별도의 DF로 저장\n",
    "london_lists_review_0 = london_lists[condition_review_0]\n",
    "\n",
    "# 리뷰 개수가 0이 아닌 컬럼 조건 설정\n",
    "condition_review = london_lists['리뷰수'] != 0\n",
    "\n",
    "# 리뷰 개수가 0이 아닌 컬럼으로 df 업데이트 \n",
    "london_lists = london_lists[condition_review]\n",
    "temp = london_lists.copy()\n",
    "\n",
    "#숙소 유형 제거 \n",
    "# 조건 설정\n",
    "condition_room_entirehomeapt = london_lists['숙소_유형'] == 'Entire home/apt'\n",
    "condition_room_privateroom = london_lists['숙소_유형'] == 'Private room'\n",
    "\n",
    "# 데이터 제거\n",
    "london_lists = london_lists[(condition_room_entirehomeapt | condition_room_privateroom)]\n",
    "\n",
    "# 예약가능여부 결측치 제거\n",
    "london_lists = london_lists[london_lists[\"예약_가능여부\"].notnull()]\n",
    "\n",
    "\n",
    "# 가격이 null값/notnull값 조건 생성 \n",
    "condition_price_notnull = london_lists['숙소_가격'].notnull()\n",
    "condition_price_null = london_lists['숙소_가격'].isnull()\n",
    "\n",
    "# 가격이 null값/null값이 아닌 df 분리\n",
    "london_lists_price = london_lists[condition_price_notnull] \n",
    "london_lists_price_null = london_lists[condition_price_null]\n",
    "\n",
    "# 변수명 정리 널값이 아닌 데이터\n",
    "london_lists = london_lists_price\n",
    "\n",
    "#슈퍼호스트 결측치 제거\n",
    "london_lists = london_lists.dropna(subset=['슈퍼호스트'])\n",
    "\n",
    "#욕실,침대,침실수 결측츠제거\n",
    "london_lists = london_lists.dropna(subset=['욕실수', '침실수', '침대수'])\n",
    "\n",
    "#리뷰점수 결측치제거\n",
    "london_lists = london_lists.dropna(subset=['숙소_정확성_리뷰점수', '숙소_청결도_리뷰점수', '숙소_체크인_리뷰점수', '숙소_소통_리뷰점수', '숙소_위치_리뷰점수', '숙소_가격_리뷰점수'])\n",
    "\n",
    "#12개월 리뷰수 0인것 제거 \n",
    "london_lists = london_lists[london_lists['12개월_리뷰수'] != 0]\n",
    "\n",
    "london_lists['숙소_가격'] = london_lists['숙소_가격'].str.lstrip('$').str.replace(',', '').astype('float')\n",
    "\n",
    "#가격이 0 인값 제거 \n",
    "london_lists = london_lists[london_lists['숙소_가격'] != 0.0]\n",
    "\n",
    "london_lists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36407, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#수용 인원수 이상치 제거 \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 이상치를 제거하는 함수 정의\n",
    "def remove_price_outliers(df, price_column, type):\n",
    "    \n",
    "    condition = (df['숙소_유형'] == type)\n",
    "    \n",
    "    if price_column != '숙소_가격':\n",
    "        Q1 = df[price_column].quantile(0.25)\n",
    "        Q3 = df[price_column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        \n",
    "        outlier = df[price_column][condition] > upper_bound\n",
    "        upper_outlier = df[condition][outlier]\n",
    "        \n",
    "        upper_outlier_indices = upper_outlier.index\n",
    "        london_lists_cleaned = df.drop(index=upper_outlier_indices, inplace=True)\n",
    "        df = london_lists_cleaned\n",
    "        return df \n",
    "    else:\n",
    "        Q1 = df[price_column].quantile(0.25)\n",
    "        Q3 = df[price_column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "        \n",
    "        outlier = df[price_column][condition] > upper_bound\n",
    "        upper_outlier = df[condition][outlier]\n",
    "        \n",
    "        upper_outlier_indices = upper_outlier.index\n",
    "        london_lists_cleaned = df.drop(index=upper_outlier_indices, inplace=True)\n",
    "        df = london_lists_cleaned\n",
    "        return df \n",
    "# 숙소 가격의 이상치 제거\n",
    "remove_price_outliers(london_lists, '수용_인원수', 'Entire home/apt')\n",
    "remove_price_outliers(london_lists, '수용_인원수', 'Private room')\n",
    "remove_price_outliers(london_lists, '숙소_가격', 'Entire home/apt')\n",
    "remove_price_outliers(london_lists, '숙소_가격', 'Private room')\n",
    "london_lists.shape # 36407개가 되어야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     https://www.airbnb.com/rooms/312761\n",
       "1                      https://www.airbnb.com/rooms/13913\n",
       "2                      https://www.airbnb.com/rooms/15400\n",
       "3                     https://www.airbnb.com/rooms/159736\n",
       "4                     https://www.airbnb.com/rooms/165336\n",
       "                               ...                       \n",
       "90451    https://www.airbnb.com/rooms/1112236129628471308\n",
       "90568    https://www.airbnb.com/rooms/1112524736745357245\n",
       "90590    https://www.airbnb.com/rooms/1113042462528003601\n",
       "90648    https://www.airbnb.com/rooms/1113966989586525761\n",
       "90735    https://www.airbnb.com/rooms/1113540860743654582\n",
       "Name: 숙소_url, Length: 36407, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_lists['숙소_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# import time\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# # 욕실, 침실, 침대수가 nan값인 숙소_id, 숙소_url 데이터의 값 7806개 \n",
    "# lodging_urls = \"https://www.airbnb.com/rooms/312761\"\n",
    "\n",
    "# #크롬 option 설정 꼭 입력!\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_experimental_option(\"detach\", True)\n",
    "# chrome_options.add_experimental_option(\"excludeSwitches\", ['enable-logging'])\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# #웹 브라우저 사이즈 고장\n",
    "# driver.set_window_size(1920, 1080)  \n",
    "\n",
    "\n",
    "\n",
    "#     listing_id, url = url_info\n",
    "#     driver.get(url)\n",
    "#     time.sleep(2) #로딩될 시간 지정 2초 \n",
    "\n",
    "#     # bs4 설정 \n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#     # 번역창 닫기\n",
    "#     try:\n",
    "#         driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"닫기\"]').click()\n",
    "#     except:\n",
    "#         pass  # 번역창이 없는 경우를 대비한 예외 처리\n",
    "    \n",
    "    \n",
    "#     # #스크롤 내리기\n",
    "#     for c in range(0,5):\n",
    "#         driver.find_element(By.TAG_NAME,'body').send_keys(Keys.PAGE_DOWN)\n",
    "#         time.sleep(1)\n",
    "        \n",
    "#     # 리뷰 모두 보기 버튼 클릭\n",
    "#     try:\n",
    "#         driver.find_element(By.XPATH, '//div[contains(@class, \"sh47dkx atm\")]').click()\n",
    "#         time.sleep(1)\n",
    "#     except:\n",
    "#         pass  # 리뷰 모두 보기 버튼이 없는 경우를 대비한 예외 처리\n",
    "    \n",
    "#     # 리뷰 크롤링\n",
    "#     try:\n",
    "#         review_container = driver.find_element(By.CSS_SELECTOR, 'div[data-testid=\"pdp-reviews-modal-scrollable-panel\"]')\n",
    "#         review_tags = review_container.find_elements(By.CSS_SELECTOR, 'div.r1are2x1')\n",
    "#         reviews = []\n",
    "#         for review_tag in review_tags:\n",
    "#             review_text_tag = review_tag.find_element(By.CSS_SELECTOR, 'span.lrl13de-atm')\n",
    "#             review_text = review_text_tag.text.strip() if review_text_tag else \"No review text found\"\n",
    "#             reviews.append(review_text)\n",
    "#             time.sleep(1) \n",
    "#     except:\n",
    "#         reviews = [\"No review container found\"]\n",
    "\n",
    "#     return listing_id, url, reviews\n",
    "\n",
    "      \n",
    "              \n",
    "        \n",
    "# results = []\n",
    "# for index, url_info in enumerate(lodging_urls[:10]):  # 1000개만 해봄\n",
    "#     print(f\"{index + 1}번째 크롤링 중..\")\n",
    "#     result = scrape_airbnb(index, url_info)\n",
    "#     results.append(result)\n",
    "#     print(result)\n",
    "#     time.sleep(6)  \n",
    "\n",
    "# # 다 돌리면 크롤링 끄기\n",
    "  \n",
    "\n",
    "# # 결과값 데이터프레임화 \n",
    "# # results_df = pd.DataFrame(results, columns=['호스트_id', '숙소_url', 'etc'])\n",
    "\n",
    "# # # csv파일로 저장\n",
    "# # results_df.to_csv('scraped_data.csv', index=False)\n",
    "\n",
    "# # print(\"Data saved to 'scraped_data_1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review_tag \u001b[38;5;129;01min\u001b[39;00m review_tags:\n\u001b[1;32m---> 95\u001b[0m     review_text_tag \u001b[38;5;241m=\u001b[39m \u001b[43mreview_tag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody > div:nth-child(19) > div > div > section > div > div > div.p1psejvv.atm_9s_1bgihbq.dir.dir-ltr > div > div._ctwstv > div > div > div > div > div > div > section > div > div._vghwkew > div > section > div._1tqgvho > div > div:nth-child(1) > div:nth-child(2) > div.r1bctolv.atm_c8_1sjzizj.atm_g3_1dgusqm.atm_26_lfmit2_13uojos.atm_5j_1y44olf_13uojos.atm_l8_1s2714j_13uojos.dir.dir-ltr > div > span > span.lrl13de.atm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m review_text_tag:\n\u001b[0;32m     97\u001b[0m         review_text \u001b[38;5;241m=\u001b[39m review_text_tag\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#크롬 option 설정 꼭 입력!\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", ['enable-logging'])\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "#웹 브라우저 사이즈 고장\n",
    "driver.set_window_size(1920, 1080)  \n",
    "\n",
    "url= 'https://www.airbnb.com/rooms/312761?source_impression_id=p3_1717237307_P30C1Pl_smoKOLn7'\n",
    "driver.get(url)\n",
    "time.sleep(2) #로딩될 시간 지정 2초 \n",
    "\n",
    "#html 다운로드 및 bs4 로 읽기 \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# 번역창 닫기\n",
    "try:\n",
    "    driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"닫기\"]').click()\n",
    "except:\n",
    "    pass  # 번역창이 없는 경우를 대비한 예외 처리\n",
    "time.sleep(2)\n",
    "\n",
    "# #스크롤 내리기\n",
    "for c in range(0,4):\n",
    "    driver.find_element(By.TAG_NAME,'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    \n",
    "# 리뷰 모두 보기 버튼 클릭\n",
    "try:\n",
    "    driver.find_element(By.XPATH, '//div[contains(@class, \"sh47dkx atm\")]').click()\n",
    "    \n",
    "except:\n",
    "    pass  # 리뷰 모두 보기 버튼이 없는 경우를 대비한 예외 처리\n",
    "    time.sleep(5)\n",
    "    \n",
    "# 모달 창이 열릴 때까지 대기\n",
    "try:\n",
    "    scroll_panel = WebDriverWait(driver, 1).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid=\"pdp-reviews-modal-scrollable-panel\"]'))\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Failed to load the reviews modal:\", e)\n",
    "    driver.quit()\n",
    "    exit()\n",
    "    \n",
    "\n",
    "# 처음에 강제로 스크롤 내리기\n",
    "driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scroll_panel)\n",
    "time.sleep(1)  # 스크롤 후 로딩을 위해 잠시 대기\n",
    "\n",
    "# 무한 스크롤을 통해 모든 리뷰를 로드\n",
    "last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scroll_panel)\n",
    "\n",
    "while True:\n",
    "    # 스크롤을 내리는 동작 (패널의 마지막 부분으로 이동)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(false);\", scroll_panel)\n",
    "    time.sleep(2)  # 스크롤 후 로딩을 위해 잠시 대기\n",
    "\n",
    "    # 새로운 스크롤 높이를 가져오기\n",
    "    new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scroll_panel)\n",
    "    \n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# 페이지 소스를 다시 BeautifulSoup으로 파싱\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# 리뷰 크롤링\n",
    "review_container = soup.find('div', {'data-testid': 'pdp-reviews-modal-scrollable-panel'})\n",
    "if review_container:\n",
    "    review_tags = review_container.find_all('div', class_='r1are2x1')\n",
    "    reviews = []\n",
    "    for review_tag in review_tags:\n",
    "        review_text_tag = review_tag.find_element(By.CSS_SELECTOR, \"body > div:nth-child(19) > div > div > section > div > div > div.p1psejvv.atm_9s_1bgihbq.dir.dir-ltr > div > div._ctwstv > div > div > div > div > div > div > section > div > div._vghwkew > div > section > div._1tqgvho > div > div:nth-child(1) > div:nth-child(2) > div.r1bctolv.atm_c8_1sjzizj.atm_g3_1dgusqm.atm_26_lfmit2_13uojos.atm_5j_1y44olf_13uojos.atm_l8_1s2714j_13uojos.dir.dir-ltr > div > span > span.lrl13de.atm\")\n",
    "        if review_text_tag:\n",
    "            review_text = review_text_tag.get_text().strip()\n",
    "        else:\n",
    "            review_text = \"No review text found\"\n",
    "        \n",
    "        reviews.append({'text': review_text})\n",
    "else:\n",
    "    reviews = []\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Reviews:\")\n",
    "for review in reviews:\n",
    "    print(f\"Stars: {review['stars']}, Review: {review['text']}\")\n",
    "\n",
    "print(len(reviews))\n",
    "\n",
    "review = soup.select('body > ul')\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from webdriver_manager) (2.32.2)\n",
      "Requirement already satisfied: python-dotenv in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from webdriver_manager) (24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from requests->webdriver_manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from requests->webdriver_manager) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\mulcam\\05_webcrawling\\.venv\\lib\\site-packages (from requests->webdriver_manager) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install webdriver_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Master\\.wdm\\drivers\\chromedriver\\win64\\125.0.6422.141\\chromedriver-win32/chromedriver.exe\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('detach', True)\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "chrome_driver = ChromeDriverManager().install()\n",
    "\n",
    "print(chrome_driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
